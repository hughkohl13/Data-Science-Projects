{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://simplyhired.com/job/GLrRc4DoH3gXxmGDQbWIN2AdgHaBQwZpPq6Aq5stAtl-IiJPQu8VXw?q=solutions+engineer\n",
      "Data Solutions Engineer Sisu At Sisu, we're building a software platform that empowers people to make better decisions using data. Based on years of cutting-edge data systems research at Stanford, the platform provides actionable insights to businesses from their data. Sisu integrates with modern data warehouses, which provide a streaming, structured view of key business metrics and their relationships with first-party organizational data. We draw on novel techniques from data mining, statistical analysis, and machine learning to produce these insights and deliver them through an elegant, modern web interface.\n",
      "\n",
      "Sisu Data is seeking a Data Solutions Engineer as part of the dynamic and strategic go-to-market team to help customers tackle critical ETL and data pipelining problems. Externally, you'll get exposure to senior leadership at a variety of companies across a variety of industries, from retail to healthcare to energy, in helping guide their decision-making with data. On our dynamic, intellectually hungry, and delightfully quirky team, the number of opportunities is unbounded.\n",
      "\n",
      "What you’ll accomplish:\n",
      "Create, maintain, and optimize data pipeline architecture internally and on behalf of our clients.\n",
      "Recommend and assemble large, complex data sets that meet business and technical requirements for extracting value out of Sisu.\n",
      "Help pave strategic roadmaps for how Sisu should approach data engineering (such as data ingestion and ETL process) and how Sisu should navigate data solutions for customers to receive maximum value from Sisu\n",
      "Identify, design, and implement internal process improvements: automating manual data processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.\n",
      "Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL on AWS (Redshift), Google Cloud Product (GCP), Snowflake, and Microsoft Azure.\n",
      "Act as analytics liaison for a variety of accounts, interacting with C-level executives down to individual analysts, to bring value to a variety of industries and use cases.\n",
      "Communicate feedback from customers’ data engineers to inform product strategy and feature work within the product and engineering teams.\n",
      "\n",
      "What you'll need to be successful:\n",
      "Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.\n",
      "Experience developing and maintaining data infrastructure for the organization\n",
      "Experience with object-oriented/object function scripting languages, Python in particular, with large datasets as a plus.\n",
      "Experience building and optimizing, including ETL/ETL process and tools, for data pipelines, architectures and data sets.\n",
      "Strong analytics skills to disentangle and find usefulness in unstructured datasets.\n",
      "Build processes supporting data transformation, data structures, metadata, dependency and workload management.\n",
      "BA/BS or heavy coursework in quantitative field preferred.\n",
      "This role is an excellent way for data engineers to get exposure to cutting edge technology and have customer-facing impact.\n",
      "\n",
      "Sisu is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status.\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "# from datetime import datetime\n",
    "import requests\n",
    "# import pymongo\n",
    "# import os\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "\n",
    "def main():\n",
    "    job_roles = [\n",
    "            'solutions+engineer',\n",
    "            'solutions+architect',\n",
    "            'sales+engineer',\n",
    "            'software+engineer',\n",
    "            'product+manager',\n",
    "            'business+analyst',\n",
    "            'data+analyst',\n",
    "            'data+scientist',\n",
    "            'data+engineer',\n",
    "            'customer+success'\n",
    "            ]\n",
    "\n",
    "    pages = (1,2,3,4,5)\n",
    "    for job_role in job_roles:\n",
    "\n",
    "        for page in pages:\n",
    "            url = 'https://www.simplyhired.com/search?q=' + job_role + '&l=' + 'San+Francisco%2C+CA'+ '&fdb=7&pn=' + str(page)\n",
    "            reqs = requests.get(url)\n",
    "        \n",
    "            soup = BeautifulSoup(reqs.text, 'html.parser')\n",
    "\n",
    "            role_card = soup.find_all('div', {'class':\"SerpJob-jobCard card\"})\n",
    "\n",
    "            urls = []\n",
    "            for card in role_card:\n",
    "                url = 'https://simplyhired.com' + card.find('a', {'class':'card-link'}, href=True)['href']\n",
    "                urls.extend([url])\n",
    "                \n",
    "            for u in urls:\n",
    "                print(u)\n",
    "                try:\n",
    "                    scrape_requests = requests.get(u)\n",
    "                    second_scrape = BeautifulSoup(scrape_requests.text, 'html.parser') \n",
    "                    role = second_scrape.find(\"h1\").text\n",
    "                    company = second_scrape.find('span', {'class':'company'}).text\n",
    "                    description = second_scrape.find('div', {'class':'viewjob-description ViewJob-description'}).text\n",
    "                    print(role,company,description)\n",
    "                except:\n",
    "                    pass\n",
    "                break\n",
    "            break\n",
    "        break\n",
    "        \n",
    "    return role, company, description, job_role, u\n",
    "\n",
    "role, company, description, job_role, u = main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'solutions+engineer'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql '\n        INSERT INTO jobs(job, role, company, description, url) VALUES (\n            solutions_engineer, Data_Solutions_Engineer, At_Sisu,_we_re_building_a_software_platform_that_empowers_people_to_make_better_decisions_using_data._Based_on_years_of_cutting-edge_data_systems_research_at_Stanford,_the_platform_provides_actionable_insights_to_businesses_from_their_data._Sisu_integrates_with_modern_data_warehouses,_which_provide_a_streaming,_structured_view_of_key_business_metrics_and_their_relationships_with_first-party_organizational_data._We_draw_on_novel_techniques_from_data_mining,_statistical_analysis,_and_machine_learning_to_produce_these_insights_and_deliver_them_through_an_elegant,_modern_web_interface.__Sisu_Data_is_seeking_a_Data_Solutions_Engineer_as_part_of_the_dynamic_and_strategic_go-to-market_team_to_help_customers_tackle_critical_ETL_and_data_pipelining_problems._Externally,_you_ll_get_exposure_to_senior_leadership_at_a_variety_of_companies_across_a_variety_of_industries,_from_retail_to_healthcare_to_energy,_in_helping_guide_their_decision-making_with_data._On_our_dynamic,_intellectually_hungry,_and_delightfully_quirky_team,_the_number_of_opportunities_is_unbounded.__What_you’ll_accomplish:_Create,_maintain,_and_optimize_data_pipeline_architecture_internally_and_on_behalf_of_our_clients._Recommend_and_assemble_large,_complex_data_sets_that_meet_business_and_technical_requirements_for_extracting_value_out_of_Sisu._Help_pave_strategic_roadmaps_for_how_Sisu_should_approach_data_engineering_(such_as_data_ingestion_and_ETL_process)_and_how_Sisu_should_navigate_data_solutions_for_customers_to_receive_maximum_value_from_Sisu_Identify,_design,_and_implement_internal_process_improvements:_automating_manual_data_processes,_optimizing_data_delivery,_re-designing_infrastructure_for_greater_scalability,_etc._Build_the_infrastructure_required_for_optimal_extraction,_transformation,_and_loading_of_data_from_a_wide_variety_of_data_sources_using_SQL_on_AWS_(Redshift),_Google_Cloud_Product_(GCP),_Snowflake,_and_Microsoft_Azure._Act_as_analytics_liaison_for_a_variety_of_accounts,_interacting_with_C-level_executives_down_to_individual_analysts,_to_bring_value_to_a_variety_of_industries_and_use_cases._Communicate_feedback_from_customers’_data_engineers_to_inform_product_strategy_and_feature_work_within_the_product_and_engineering_teams.__What_you_ll_need_to_be_successful:_Advanced_working_SQL_knowledge_and_experience_working_with_relational_databases,_query_authoring_(SQL)_as_well_as_working_familiarity_with_a_variety_of_databases._Experience_developing_and_maintaining_data_infrastructure_for_the_organization_Experience_with_object-oriented/object_function_scripting_languages,_Python_in_particular,_with_large_datasets_as_a_plus._Experience_building_and_optimizing,_including_ETL/ETL_process_and_tools,_for_data_pipelines,_architectures_and_data_sets._Strong_analytics_skills_to_disentangle_and_find_usefulness_in_unstructured_datasets._Build_processes_supporting_data_transformation,_data_structures,_metadata,_dependency_and_workload_management._BA/BS_or_heavy_coursework_in_quantitative_field_preferred._This_role_is_an_excellent_way_for_data_engineers_to_get_exposure_to_cutting_edge_technology_and_have_customer-facing_impact.__Sisu_is_committed_to_creating_a_diverse_environment_and_is_proud_to_be_an_equal_opportunity_employer._All_qualified_applicants_will_receive_consideration_for_employment_without_regard_to_race,_color,_religion,_gender,_gender_identity_or_expression,_sexual_orientation,_national_origin,_genetics,_disability,_age,_or_veteran_status., dogs, https://simplyhired.com/job/GLrRc4DoH3gXxmGDQbWIN2AdgHaBQwZpPq6Aq5stAtl-IiJPQu8VXw?q=solutions+engineer)\n        ': near \"to\": syntax error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1594\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1595\u001b[0;31m                 \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1596\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcur\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperationalError\u001b[0m: near \"to\": syntax error",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-3ddcf16d3565>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m             {}, {}, {}, dogs, {})\n\u001b[1;32m      6\u001b[0m         '''.format(job_role.replace('+', '_'), role.replace(' ', '_'), description.replace('\\n', ' ').replace(' ', '_').replace(\"'\", '_'), u)\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_sql_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mread_sql_query\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0mcoerce_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_dates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m     )\n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mread_query\u001b[0;34m(self, sql, index_col, coerce_float, params, parse_dates, chunksize)\u001b[0m\n\u001b[1;32m   1643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1644\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1645\u001b[0;31m         \u001b[0mcursor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcol_desc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol_desc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1608\u001b[0m                 \u001b[0;34m\"Execution failed on sql '{sql}': {exc}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1609\u001b[0m             )\n\u001b[0;32m-> 1610\u001b[0;31m             \u001b[0mraise_with_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1612\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/compat/__init__.py\u001b[0m in \u001b[0;36mraise_with_traceback\u001b[0;34m(exc, traceback)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtraceback\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mEllipsis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1593\u001b[0m                 \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1595\u001b[0;31m                 \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1596\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcur\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDatabaseError\u001b[0m: Execution failed on sql '\n        INSERT INTO jobs(job, role, company, description, url) VALUES (\n            solutions_engineer, Data_Solutions_Engineer, At_Sisu,_we_re_building_a_software_platform_that_empowers_people_to_make_better_decisions_using_data._Based_on_years_of_cutting-edge_data_systems_research_at_Stanford,_the_platform_provides_actionable_insights_to_businesses_from_their_data._Sisu_integrates_with_modern_data_warehouses,_which_provide_a_streaming,_structured_view_of_key_business_metrics_and_their_relationships_with_first-party_organizational_data._We_draw_on_novel_techniques_from_data_mining,_statistical_analysis,_and_machine_learning_to_produce_these_insights_and_deliver_them_through_an_elegant,_modern_web_interface.__Sisu_Data_is_seeking_a_Data_Solutions_Engineer_as_part_of_the_dynamic_and_strategic_go-to-market_team_to_help_customers_tackle_critical_ETL_and_data_pipelining_problems._Externally,_you_ll_get_exposure_to_senior_leadership_at_a_variety_of_companies_across_a_variety_of_industries,_from_retail_to_healthcare_to_energy,_in_helping_guide_their_decision-making_with_data._On_our_dynamic,_intellectually_hungry,_and_delightfully_quirky_team,_the_number_of_opportunities_is_unbounded.__What_you’ll_accomplish:_Create,_maintain,_and_optimize_data_pipeline_architecture_internally_and_on_behalf_of_our_clients._Recommend_and_assemble_large,_complex_data_sets_that_meet_business_and_technical_requirements_for_extracting_value_out_of_Sisu._Help_pave_strategic_roadmaps_for_how_Sisu_should_approach_data_engineering_(such_as_data_ingestion_and_ETL_process)_and_how_Sisu_should_navigate_data_solutions_for_customers_to_receive_maximum_value_from_Sisu_Identify,_design,_and_implement_internal_process_improvements:_automating_manual_data_processes,_optimizing_data_delivery,_re-designing_infrastructure_for_greater_scalability,_etc._Build_the_infrastructure_required_for_optimal_extraction,_transformation,_and_loading_of_data_from_a_wide_variety_of_data_sources_using_SQL_on_AWS_(Redshift),_Google_Cloud_Product_(GCP),_Snowflake,_and_Microsoft_Azure._Act_as_analytics_liaison_for_a_variety_of_accounts,_interacting_with_C-level_executives_down_to_individual_analysts,_to_bring_value_to_a_variety_of_industries_and_use_cases._Communicate_feedback_from_customers’_data_engineers_to_inform_product_strategy_and_feature_work_within_the_product_and_engineering_teams.__What_you_ll_need_to_be_successful:_Advanced_working_SQL_knowledge_and_experience_working_with_relational_databases,_query_authoring_(SQL)_as_well_as_working_familiarity_with_a_variety_of_databases._Experience_developing_and_maintaining_data_infrastructure_for_the_organization_Experience_with_object-oriented/object_function_scripting_languages,_Python_in_particular,_with_large_datasets_as_a_plus._Experience_building_and_optimizing,_including_ETL/ETL_process_and_tools,_for_data_pipelines,_architectures_and_data_sets._Strong_analytics_skills_to_disentangle_and_find_usefulness_in_unstructured_datasets._Build_processes_supporting_data_transformation,_data_structures,_metadata,_dependency_and_workload_management._BA/BS_or_heavy_coursework_in_quantitative_field_preferred._This_role_is_an_excellent_way_for_data_engineers_to_get_exposure_to_cutting_edge_technology_and_have_customer-facing_impact.__Sisu_is_committed_to_creating_a_diverse_environment_and_is_proud_to_be_an_equal_opportunity_employer._All_qualified_applicants_will_receive_consideration_for_employment_without_regard_to_race,_color,_religion,_gender,_gender_identity_or_expression,_sexual_orientation,_national_origin,_genetics,_disability,_age,_or_veteran_status., dogs, https://simplyhired.com/job/GLrRc4DoH3gXxmGDQbWIN2AdgHaBQwZpPq6Aq5stAtl-IiJPQu8VXw?q=solutions+engineer)\n        ': near \"to\": syntax error"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect(\"/Users/hughkohl/Desktop/web_crawler/web-crawler/job.db\")\n",
    "\n",
    "sql =   '''\n",
    "        INSERT INTO jobs(job, role, company, description, url) VALUES (\n",
    "            {}, {}, {}, dogs, {})\n",
    "        '''.format(job_role.replace('+', '_'), role.replace(' ', '_'), description.replace('\\n', ' ').replace(' ', '_').replace(\"'\", '_'), u)\n",
    "pd.read_sql_query(sql,conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
